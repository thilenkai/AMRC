T0,
type = 3,          # Aligns the split labels with the branches
extra = 104,       # Shows the class probabilities at each node
under = TRUE,      # Places labels under the nodes
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 106, cex = 0.8, box.palette = "Blues", shadow.col = "gray")
rpart.plot(
T0,
type = 3,          # Aligns the split labels with the branches
extra = 104,       # Shows the class probabilities at each node
under = TRUE,      # Places labels under the nodes
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
plot(T0)
text(T0, pretty = 0)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 106, cex = 0.8, box.palette = "Blues", shadow.col = "gray")
rpart.plot(
T0,
type = 3,          # Aligns the split labels with the branches
extra = 106,       # Shows the class probabilities at each node
under = TRUE,      # Places labels under the nodes
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
plot(T0)
text(T0, pretty = 0)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 104, cex = 0.8, box.palette = "Blues", shadow.col = "gray")
rpart.plot(
T0,
type = 3,          # Aligns the split labels with the branches
extra = 106,       # Shows the class probabilities at each node
under = TRUE,      # Places labels under the nodes
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
plot(T0)
text(T0, pretty = 0)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 106, cex = 0.8, box.palette = "Blues", shadow.col = "gray")
rpart.plot(
T0,
type = 3,          # Aligns the split labels with the branches
extra = 106,       # Shows the class probabilities at each node
under = TRUE,      # Places labels under the nodes
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
plot(T0)
text(T0, pretty = 0)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 104, cex = 0.8, box.palette = "Blues", shadow.col = "gray")
rpart.plot(
T0,
type = 3,          # Aligns the split labels with the branches
extra = 106,       # Shows the class probabilities at each node
under = TRUE,      # Places labels under the nodes
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
plot(T0)
text(T0, pretty = 0)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 106, under = TRUE, cex = 0.8, box.palette = "Blues", shadow.col = "gray")
rpart.plot(
T0,
type = 3,          # Aligns the split labels with the branches
extra = 106,       # Shows the class probabilities at each node
under = TRUE,      # Places labels under the nodes
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 106, cex = 0.8, box.palette = "Blues", shadow.col = "gray")
rpart.plot(
T0,
type = 3,          # Aligns the split labels with the branches
extra = 106,       # Shows the class probabilities at each node
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 106, cex = 0.3, box.palette = "Blues", shadow.col = "gray")
rpart.plot(
T0,
type = 3,          # Aligns the split labels with the branches
extra = 106,       # Shows the class probabilities at each node
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 106, cex = 0.4, box.palette = "Blues", shadow.col = "gray")
rpart.plot(
T0,
type = 3,          # Aligns the split labels with the branches
extra = 106,       # Shows the class probabilities at each node
cex = 0.6,         # Reduces the size of the text
box.palette = "RdBu", # Use a better color palette
shadow.col = 0,    # Removes shadows for a cleaner look
split.cex = 0.7,   # Adjusts text size for split labels
split.box.col = "lightblue", # Adds a background color to split labels
split.border.col = "darkgray", # Border color for split labels
fallen.leaves = TRUE # Arranges the leaves at the bottom
)
# Plot the tree with better formatting
rpart.plot(T0, type = 2, extra = 106, cex = 0.4, box.palette = "Blues", shadow.col = "gray")
# Predict the class for the test set
predictions <- predict(T0, test_data, type = "class")
# Create the confusion matrix
library(caret)  # Load the caret package for evaluation metrics
conf_matrix <- confusionMatrix(predictions, test_data$Purchase, positive = "Yes")
# Display the confusion matrix
print(conf_matrix$table)
# Report the balanced accuracy
balanced_accuracy <- conf_matrix$byClass["Balanced Accuracy"]
cat("Balanced Accuracy:", balanced_accuracy, "\n")
# Predict on test set
pred_initial <- predict(T0, test_data, type = "class")
# Confusion matrix and balanced accuracy
conf_matrix_initial <- confusionMatrix(pred_initial, test_data$Purchase, positive = "Yes")
conf_matrix_initial$table
conf_matrix_initial$byClass["Balanced Accuracy"]
# Predict the class for the test set
predictions <- predict(T0, test_data, type = "class")
# Create the confusion matrix
library(caret)  # Load the caret package for evaluation metrics
conf_matrix <- confusionMatrix(predictions, test_data$Purchase, positive = "Yes")
# Display the confusion matrix
print(conf_matrix$table)
# Report the balanced accuracy
balanced_accuracy <- conf_matrix$byClass["Balanced Accuracy"]
cat("Balanced Accuracy:", balanced_accuracy, "\n")
# Plot cross-validation results
plotcp(T0)
# Print the complexity parameter (CP) table
printcp(T0)
# Identify the optimal CP
optimal_cp <- T0$cptable[which.min(T0$cptable[, "xerror"]), "CP"]
cat("Optimal Complexity Parameter (CP):", optimal_cp, "\n")
# Prune the tree using the optimal CP
optimal_cp <- 0.0071839  # From the previous analysis
pruned_tree <- prune(T0, cp = optimal_cp)
# Visualize the pruned tree
plot(pruned_tree)
text(pruned_tree, pretty = 0)
# Prune the tree using the optimal CP
optimal_cp <- 0.0071839
pruned_tree <- prune(T0, cp = optimal_cp)
# Visualize the pruned tree
plot(pruned_tree)
text(pruned_tree, pretty = 0)
# Prune the tree using the optimal CP
optimal_cp <- 0.0071839
pruned_tree <- prune(T0, cp = optimal_cp)
# Visualize the pruned tree
plot(pruned_tree)
text(pruned_tree, pretty = 0)
# Plot the tree with better formatting
rpart.plot(pruned_tree, type = 2, extra = 106, cex = 0.4,
box.palette = "Blues", shadow.col = "gray")
# Prune the tree using the optimal CP
optimal_cp <- 0.0071839
pruned_tree <- prune(T0, cp = optimal_cp)
# Visualize the pruned tree
plot(pruned_tree)
text(pruned_tree, pretty = 0)
# Plot the tree with better formatting
rpart.plot(pruned_tree, type = 2, extra = 106, cex = 0.6,
box.palette = "Blues", shadow.col = "gray")
# Predict on the test set using the pruned tree
pred_pruned <- predict(pruned_tree, test_data, type = "class")
# Create the confusion matrix
conf_matrix_pruned <- confusionMatrix(pred_pruned, test_data$Purchase, positive = "Yes")
# Display the confusion matrix
print(conf_matrix_pruned$table)
# Report the balanced accuracy
balanced_accuracy_pruned <- conf_matrix_pruned$byClass["Balanced Accuracy"]
cat("Balanced Accuracy (Pruned Tree):", balanced_accuracy_pruned, "\n")
# Assign weights: higher for the minority class ("Yes")
weights <- ifelse(train_data$Purchase == "Yes", 10, 1)
# Build the weighted decision tree
weighted_tree <- rpart(Purchase ~ ., data = train_data, method = "class",
weights = weights, control = rpart.control(cp = 0.001, minsplit = 10))
# Predict on the test set
pred_weighted <- predict(weighted_tree, test_data, type = "class")
# Confusion matrix and balanced accuracy
conf_matrix_weighted <- confusionMatrix(pred_weighted, test_data$Purchase, positive = "Yes")
print(conf_matrix_weighted$table)
cat("Balanced Accuracy (Weighted Tree):", conf_matrix_weighted$byClass["Balanced Accuracy"], "\n")
# Build a Random Forest model
rf_model <- randomForest(Purchase ~ ., data = train_data, ntree = 500, importance = TRUE)
# Predict on the test set
rf_predictions <- predict(rf_model, test_data)
# Create the confusion matrix
rf_conf_matrix <- confusionMatrix(rf_predictions, test_data$Purchase, positive = "Yes")
# Display the confusion matrix
print(rf_conf_matrix$table)
# Report the balanced accuracy
rf_balanced_accuracy <- rf_conf_matrix$byClass["Balanced Accuracy"]
cat("Balanced Accuracy (Random Forest):", rf_balanced_accuracy, "\n")
# Plot the Random Forest result
plot(rf_model)
rf_sampsize <- randomForest(Purchase ~ ., data = train_data, sampsize = c(100, 100))
pred_sampsize <- predict(rf_sampsize, test_data)
conf_matrix_sampsize <- confusionMatrix(pred_sampsize, test_data$Purchase, positive = "Yes")
conf_matrix_sampsize$byClass["Balanced Accuracy"]
rf_classwt <- randomForest(Purchase ~ ., data = train_data, classwt = c(0.3, 0.7))
pred_classwt <- predict(rf_classwt, test_data)
conf_matrix_classwt <- confusionMatrix(pred_classwt, test_data$Purchase, positive = "Yes")
conf_matrix_classwt$byClass["Balanced Accuracy"]
rf_cutoff <- randomForest(Purchase ~ ., data = train_data, cutoff = c(0.3, 0.7))
pred_cutoff <- predict(rf_cutoff, test_data)
conf_matrix_cutoff <- confusionMatrix(pred_cutoff, test_data$Purchase, positive = "Yes")
conf_matrix_cutoff$byClass["Balanced Accuracy"]
# Run the Random Forest with the best strategy (e.g., sampsize) and importance = TRUE
rf_best <- randomForest(Purchase ~ ., data = train_data,
sampsize = c(100, 100), # Replace with your best strategy
importance = TRUE, ntree = 500)
# Predict on the test set
pred_best <- predict(rf_best, test_data)
# Evaluate the model
conf_matrix_best <- confusionMatrix(pred_best, test_data$Purchase, positive = "Yes")
cat("Balanced Accuracy (Best Random Forest):", conf_matrix_best$byClass["Balanced Accuracy"], "\n")
# Plot the Random Forest result
plot(rf_best)
# Plot variable importance
varImpPlot(rf_best)
R.version.string
install.packages(c("MCMCpack", "mvtnorm", "coda", "truncnorm"))
install.packages("DPpackage_1.1-7.tar.gz", repos = NULL, type = "source")
install.packages("DPpackage_1.1-7.tar.gz", repos = NULL, type = "source")
install.packages("DPpackage_1.1-7.tar.gz", repos = NULL, type = "source")
install.packages("DPpackage/DPpackage_1.1-7_patched.tar.tar.gz", repos = NULL, type = "source")
install.packages("DPpackage/DPpackage_1.1-7_patched.tar.gz", repos = NULL, type = "source")
install.packages("DPpackage/package_1.1-7_patched.tar.gz", repos = NULL, type = "source")
install.packages("C:\Users\Admin\Desktop\TUWien\semester_3\Statistical Simulation and Computerintensive Methods\DPpackage\DPpackage_1.1-7_patched.tar.gz", repos = NULL, type = "source")
install.packages("DPpackage\DPpackage_1.1-7_patched.tar.gz", repos = NULL, type = "source")
install.packages("DPpackage/DPpackage_1.1-7_patched.tar.gz", repos = NULL, type = "source")
install.packages("package_1.1-7_patched.tar.gz", repos = NULL, type = "source")
install.packages("package_1.1-7_patched.tar.gz", repos = NULL, type = "source")
install.packages("package_1.1-7_patched.tar", repos = NULL, type = "source")
install.packages("package_1.1-7_patched.tar", repos = NULL, type = "source")
install.packages("package_1.1-7_patched.tar", repos = NULL, type = "source")
# Set global options for all code chunks
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, tidy = TRUE)
library(e1071)
library(caret)
bank_data <- read.csv("bank.csv")
# Convert y to a factor
bank_data$y <- as.factor(bank_data$y)
# Load caret package
library(caret)
# Load the dataset
bank_data <- read.csv("bank.csv")
# Ensure `y` is converted to a factor
bank_data$y <- as.factor(bank_data$y)
library(e1071)
library(caret)
bank_data <- read.csv2("bank.csv")
# Exclude the variable 'duration'
bank_data <- bank_data[, !colnames(bank_data) %in% "duration"]
# Convert y to a factor
bank_data$y <- as.factor(bank_data$y)
# Check class distribution
table(bank_data$y)
# Set seed for reproducibility
set.seed(123)
# Stratified split for training and testing
data_split <- createDataPartition(bank_data$y, p = 0.67, list = FALSE)
train_data <- bank_data[data_split, ]
test_data <- bank_data[-data_split, ]
# Train SVM with default parameters
svm_model <- svm(y ~ ., data = train_data, kernel = "radial")
# Predict on test data
predictions <- predict(svm_model, newdata = test_data)
# Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_data$y)
conf_matrix
# Calculate Balanced Accuracy
balanced_acc <- (conf_matrix$byClass["Sensitivity"] + conf_matrix$byClass["Specificity"]) / 2
balanced_acc
# Define parameter grid
grid <- expand.grid(gamma = 2^(-1:1), cost = 2^(0:2))
# Tune SVM
svm_tune <- tune.svm(y ~ ., data = train_data, gamma = grid$gamma, cost = grid$cost)
# Set global options for all code chunks
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, tidy = TRUE)
library(e1071)
library(caret)
bank_data <- read.csv2("bank.csv")
# Exclude the variable 'duration'
bank_data <- bank_data[, !colnames(bank_data) %in% "duration"]
# Convert y to a factor
bank_data$y <- as.factor(bank_data$y)
# Check class distribution
table(bank_data$y)
# Set seed for reproducibility
set.seed(123)
# Stratified split for training and testing
data_split <- createDataPartition(bank_data$y, p = 0.67, list = FALSE)
train_data <- bank_data[data_split, ]
test_data <- bank_data[-data_split, ]
# Train SVM with default parameters
svm_model <- svm(y ~ ., data = train_data, kernel = "radial")
# Predict on test data
predictions <- predict(svm_model, newdata = test_data)
# Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_data$y)
conf_matrix
# Calculate Balanced Accuracy
balanced_acc <- (conf_matrix$byClass["Sensitivity"] + conf_matrix$byClass["Specificity"]) / 2
balanced_acc
# Define the parameter grid for gamma and cost
gamma_values <- 2^(-5:1)  # Gamma values from 2^-5 to 2^1
cost_values <- 2^(0:5)    # Cost values from 2^0 to 2^5
# Tune SVM
svm_tuning <- tune.svm(
y ~ .,
data = train_data,
kernel = "radial",
gamma = gamma_values,
cost = cost_values
)
# Set global options for all code chunks
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, tidy = TRUE)
library(e1071)
library(caret)
bank_data <- read.csv2("bank.csv")
# Exclude the variable 'duration'
bank_data <- bank_data[, !colnames(bank_data) %in% "duration"]
# Convert y to a factor
bank_data$y <- as.factor(bank_data$y)
# Check class distribution
table(bank_data$y)
# Set seed for reproducibility
set.seed(123)
# Stratified split for training and testing
data_split <- createDataPartition(bank_data$y, p = 0.67, list = FALSE)
train_data <- bank_data[data_split, ]
test_data <- bank_data[-data_split, ]
# Train SVM with default parameters
svm_model <- svm(y ~ ., data = train_data, kernel = "radial")
# Predict on test data
predictions <- predict(svm_model, newdata = test_data)
# Confusion Matrix
conf_matrix <- confusionMatrix(predictions, test_data$y)
conf_matrix
# Calculate Balanced Accuracy
balanced_acc <- (conf_matrix$byClass["Sensitivity"] + conf_matrix$byClass["Specificity"]) / 2
balanced_acc
# Define the parameter grid for gamma and cost
gamma_values <- 2^(-5:1)  # Gamma values from 2^-5 to 2^1
cost_values <- 2^(0:5)    # Cost values from 2^0 to 2^5
# Tune SVM
svm_tuning <- tune.svm(
y ~ .,
data = train_data,
kernel = "radial",
gamma = gamma_values,
cost = cost_values
)
# View the best parameters
svm_tuning$best.parameters
# Plot the tuning results to visualize misclassification error
plot(svm_tuning)
# Use the best model
best_model <- svm_tune$best.model
# Use the best model
best_model <- svm_tune$best.model
# Use the best model from the tuning process
best_model <- svm_tuning$best.model
# Predict the group membership for the test data
best_predictions <- predict(best_model, newdata = test_data)
# Confusion Matrix
best_conf_matrix <- confusionMatrix(best_predictions, test_data$y)
print(best_conf_matrix)
# Calculate Balanced Accuracy
best_balanced_acc <- (best_conf_matrix$byClass["Sensitivity"] + best_conf_matrix$byClass["Specificity"]) / 2
cat("Balanced Accuracy for the Best Model:", best_balanced_acc, "\n")
# Define class weights
class_weights <- list("no" = 1, "yes" = 5)
# Define error function
balanced_error <- function(pred, obs) {
confusion <- table(pred, obs)
sensitivity <- confusion["yes", "yes"] / sum(confusion[, "yes"])
specificity <- confusion["no", "no"] / sum(confusion[, "no"])
1 - (sensitivity + specificity) / 2
}
# Tune SVM with class weights
svm_weight_tune <- tune(
svm,
y ~ .,
data = train_data,
kernel = "radial",
class.weights = class_weights,
ranges = list(gamma = 2^(-1:1), cost = 2^(0:2)),
tunecontrol = tune.control(sampling = "cross", error.fun = balanced_error)
)
# Best parameters
svm_weight_tune$best.parameters
# Use the best model
weighted_model <- svm_weight_tune$best.model
# Predict on test data
weighted_predictions <- predict(weighted_model, newdata = test_data)
# Confusion Matrix
weighted_conf_matrix <- confusionMatrix(weighted_predictions, test_data$y)
weighted_conf_matrix
# Calculate Balanced Accuracy
weighted_balanced_acc <- (weighted_conf_matrix$byClass["Sensitivity"] + weighted_conf_matrix$byClass["Specificity"]) / 2
weighted_balanced_acc
# Define the class weights to give more importance to the minority class
class_weights <- list("no" = 1, "yes" = 5)
# Define the custom error function for balanced accuracy
balanced_error <- function(pred, obs) {
confusion <- table(pred, obs)
sensitivity <- confusion["no", "no"] / sum(confusion[, "no"])
specificity <- confusion["yes", "yes"] / sum(confusion[, "yes"])
1 - (sensitivity + specificity) / 2
}
# Tune SVM with class weights
svm_weight_tuning <- tune(
svm,
y ~ .,
data = train_data,
kernel = "radial",
ranges = list(gamma = 2^(-5:1), cost = 2^(0:5)),
class.weights = class_weights,
tunecontrol = tune.control(sampling = "cross", error.fun = balanced_error)
)
# Best parameters from the tuning
svm_weight_tuning$best.parameters
# Define the class weights to give more importance to the minority class
class_weights <- list("no" = 1, "yes" = 5)
# Define the custom error function for balanced accuracy
balanced_error <- function(pred, obs) {
confusion <- table(pred, obs)
sensitivity <- confusion["no", "no"] / sum(confusion[, "no"])
specificity <- confusion["yes", "yes"] / sum(confusion[, "yes"])
1 - (sensitivity + specificity) / 2
}
# Tune SVM with class weights
svm_weight_tuning <- tune(
svm,
y ~ .,
data = train_data,
kernel = "radial",
ranges = list(gamma = 2^(-5:1), cost = 2^(0:5)),
class.weights = class_weights,
tunecontrol = tune.control(sampling = "cross", error.fun = balanced_error)
)
# Best parameters from the tuning
svm_weight_tuning$best.parameters
# Use the best model from weighted tuning
weighted_model <- svm_weight_tuning$best.model
# Predict on test data
weighted_predictions <- predict(weighted_model, newdata = test_data)
# Confusion Matrix
weighted_conf_matrix <- confusionMatrix(weighted_predictions, test_data$y)
print(weighted_conf_matrix)
# Calculate Balanced Accuracy
weighted_balanced_acc <- (weighted_conf_matrix$byClass["Sensitivity"] + weighted_conf_matrix$byClass["Specificity"]) / 2
cat("Balanced Accuracy with Class Weights:", weighted_balanced_acc, "\n")
